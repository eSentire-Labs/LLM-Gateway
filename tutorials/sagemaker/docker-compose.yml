# This docker-compose file starts up the api, chat client, and a docker postgres container

version: '3.8'

services:
  api:
    container_name: llm-gateway-api
    build: ./backend/
    command: bash -c 'cd ./backend; uvicorn src.app:app --host 0.0.0.0'
    volumes:
      - .:/app
    ports:
      - 8008:8000
    environment:
      - DATABASE_URL=postgresql://fastapi_traefik:fastapi_traefik@db:5432/fastapi_traefik
      - LLM_API_CONTENT_TYPE=application/json
      - LLM_ENDPOINT=[AWS API Gateway URL. E.g. protocol://service-code.region-code.amazonaws.com] # LLM endpoint you want to proxy to
      - LLM_IMG_ENDPOINT=https://api.openai.com/v1/images/generations # Another llm endpoint you want to proxy to
      - LLM_API_AUTHORIZATION=Bearer [LLM TOKEN/API KEY HERE. E.g. Bearer sk-asda...]
      - ENABLE_SUBMISSIONS_API=false # True of an API is enabled to send logs to eSentire
      - SUBMISSIONS_API_URL=[SUBMISSIONS URL PROVIDED IF CONFIGURED] # The URL provided by eSentire if llm log submissions is enabled
    networks:
      - llm-demo
    depends_on:
      db:
        condition: service_healthy
  db:
    container_name: llm-gateway-db
    image: postgres:15-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    expose:
      - 5432
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=fastapi_traefik
      - POSTGRES_PASSWORD=fastapi_traefik
      - POSTGRES_DB=fastapi_traefik
    networks:
      - llm-demo
    healthcheck: # This health check is necessary so that we can accurately determin that the service is ready before starting the api
      test: ["CMD-SHELL", "pg_isready -U fastapi_traefik"] 
      interval: 10s
      timeout: 5s
      retries: 5
  frontend:
    container_name: llm-gateway-chat
    build: ./frontend/
    environment:
      - LLM_GATEWAY_URL=http://llm-gateway-api:8000 # Replace this with your internal LLM Gateway Proxy url. This default value is currently pointing to the backend api docker container
    networks: 
      - llm-demo
    ports:
      - 3000:3000

volumes:
  postgres_data:

networks:
  llm-demo: 
